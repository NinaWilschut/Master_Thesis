{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_in_mave_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "data['title embeddings'] = ''\n",
    "\n",
    "a = 0\n",
    "for row in data['title']:\n",
    "    title_embed = model.encode(row)\n",
    "    data.at[a, 'title embeddings'] = title_embed\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>diffbotUri</th>\n",
       "      <th>specs</th>\n",
       "      <th>in_mave</th>\n",
       "      <th>category</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>title embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Master Craft 1.6 Liter Copper Watering Can</td>\n",
       "      <td>product|4|-1893862752</td>\n",
       "      <td>{'producttypename': 'OUTDOOR_LIVING', 'binding...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Patio, Lawn &amp; Garden', 'Gardening &amp; Lawn Car...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>[-0.28141925, 0.2698027, 0.1100372, 0.86912847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>The Portable Henry Rollins</td>\n",
       "      <td>product|4|-1343189524</td>\n",
       "      <td>{'paperback': '320 pages'}</td>\n",
       "      <td>True</td>\n",
       "      <td>['Books', 'Literature &amp; Fiction', 'Genre Ficti...</td>\n",
       "      <td>Books</td>\n",
       "      <td>[-0.45946708, 0.36189297, -0.25941432, -0.2868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Tamron SP 24-70mm Di VC USD Nikon Mount (Model...</td>\n",
       "      <td>product|4|564903833</td>\n",
       "      <td>{'focus_type': 'Ultrasonic', 'minimum_aperture...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Electronics', 'eBook Readers &amp; Accessories',...</td>\n",
       "      <td>Books</td>\n",
       "      <td>[-0.6068507, 0.34362677, 0.1731695, -0.3007811...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Made by Dad: 67 Blueprints for Making Cool Stuff</td>\n",
       "      <td>product|4|-1826877188</td>\n",
       "      <td>{'paperback': '336 pages'}</td>\n",
       "      <td>True</td>\n",
       "      <td>['Books', 'Biographies &amp; Memoirs', 'Arts &amp; Lit...</td>\n",
       "      <td>Books</td>\n",
       "      <td>[-1.2025808, 0.14240591, 0.12302717, -0.164819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>Kai to the Rescue!</td>\n",
       "      <td>product|4|336878652</td>\n",
       "      <td>{'grade_level': 'Preschool - Kindergarten', 'h...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Books', 'Literature &amp; Fiction', 'Genre Ficti...</td>\n",
       "      <td>Books</td>\n",
       "      <td>[-0.38582692, 0.8587187, 0.15365739, 0.2423255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2078</td>\n",
       "      <td>Light Accents, Table Lamp 18.5 Inches Height, ...</td>\n",
       "      <td>product|4|-1280935066</td>\n",
       "      <td>{'shade_material': 'Fabric', 'finish': 'Bronze...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Tools &amp; Home Improvement', 'Lighting &amp; Ceili...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>[-0.100550376, 0.63713616, 0.069718584, 0.6708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2106</td>\n",
       "      <td>The Routes Not Taken: A Trip Through New York ...</td>\n",
       "      <td>product|4|-1612441828</td>\n",
       "      <td>{'hardcover': '336 pages'}</td>\n",
       "      <td>True</td>\n",
       "      <td>['Books', 'Literature &amp; Fiction', 'Genre Ficti...</td>\n",
       "      <td>Books</td>\n",
       "      <td>[0.35349807, -0.8391143, 0.31275266, 0.2153156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2116</td>\n",
       "      <td>Pono Music Portable Music Player, Black</td>\n",
       "      <td>product|4|277356526</td>\n",
       "      <td>{'batteries_included': 'Yes', 'batteries': '1 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Electronics', 'Portable Audio &amp; Video', 'MP3...</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>[-0.38823387, -0.20821722, 0.10322529, -0.0668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2146</td>\n",
       "      <td>Out of Stock</td>\n",
       "      <td>product|4|725874185</td>\n",
       "      <td>{'casters_included': 'Yes', 'finish': 'Grey', ...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Clothing, Shoes &amp; Jewelry', 'Luggage &amp; Trave...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.24847102, 0.30055243, -0.19379012, 0.12391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2166</td>\n",
       "      <td>Carlson 14193 Front Brake Caliper Bolt and Pin</td>\n",
       "      <td>product|4|-303886263</td>\n",
       "      <td>{'product_weight': '100 hundredths-pounds', 'p...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Automotive', 'Replacement Parts', 'Brake Sys...</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>[-0.5370231, -0.16296385, -0.42152908, -0.3307...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              title  \\\n",
       "0           10         Master Craft 1.6 Liter Copper Watering Can   \n",
       "1           23                         The Portable Henry Rollins   \n",
       "2           41  Tamron SP 24-70mm Di VC USD Nikon Mount (Model...   \n",
       "3           74   Made by Dad: 67 Blueprints for Making Cool Stuff   \n",
       "4           82                                 Kai to the Rescue!   \n",
       "..         ...                                                ...   \n",
       "70        2078  Light Accents, Table Lamp 18.5 Inches Height, ...   \n",
       "71        2106  The Routes Not Taken: A Trip Through New York ...   \n",
       "72        2116            Pono Music Portable Music Player, Black   \n",
       "73        2146                                       Out of Stock   \n",
       "74        2166     Carlson 14193 Front Brake Caliper Bolt and Pin   \n",
       "\n",
       "               diffbotUri                                              specs  \\\n",
       "0   product|4|-1893862752  {'producttypename': 'OUTDOOR_LIVING', 'binding...   \n",
       "1   product|4|-1343189524                         {'paperback': '320 pages'}   \n",
       "2     product|4|564903833  {'focus_type': 'Ultrasonic', 'minimum_aperture...   \n",
       "3   product|4|-1826877188                         {'paperback': '336 pages'}   \n",
       "4     product|4|336878652  {'grade_level': 'Preschool - Kindergarten', 'h...   \n",
       "..                    ...                                                ...   \n",
       "70  product|4|-1280935066  {'shade_material': 'Fabric', 'finish': 'Bronze...   \n",
       "71  product|4|-1612441828                         {'hardcover': '336 pages'}   \n",
       "72    product|4|277356526  {'batteries_included': 'Yes', 'batteries': '1 ...   \n",
       "73    product|4|725874185  {'casters_included': 'Yes', 'finish': 'Grey', ...   \n",
       "74   product|4|-303886263  {'product_weight': '100 hundredths-pounds', 'p...   \n",
       "\n",
       "    in_mave                                           category  \\\n",
       "0      True  ['Patio, Lawn & Garden', 'Gardening & Lawn Car...   \n",
       "1      True  ['Books', 'Literature & Fiction', 'Genre Ficti...   \n",
       "2      True  ['Electronics', 'eBook Readers & Accessories',...   \n",
       "3      True  ['Books', 'Biographies & Memoirs', 'Arts & Lit...   \n",
       "4      True  ['Books', 'Literature & Fiction', 'Genre Ficti...   \n",
       "..      ...                                                ...   \n",
       "70     True  ['Tools & Home Improvement', 'Lighting & Ceili...   \n",
       "71     True  ['Books', 'Literature & Fiction', 'Genre Ficti...   \n",
       "72     True  ['Electronics', 'Portable Audio & Video', 'MP3...   \n",
       "73     True  ['Clothing, Shoes & Jewelry', 'Luggage & Trave...   \n",
       "74     True  ['Automotive', 'Replacement Parts', 'Brake Sys...   \n",
       "\n",
       "           main_cat                                   title embeddings  \n",
       "0       Amazon Home  [-0.28141925, 0.2698027, 0.1100372, 0.86912847...  \n",
       "1             Books  [-0.45946708, 0.36189297, -0.25941432, -0.2868...  \n",
       "2             Books  [-0.6068507, 0.34362677, 0.1731695, -0.3007811...  \n",
       "3             Books  [-1.2025808, 0.14240591, 0.12302717, -0.164819...  \n",
       "4             Books  [-0.38582692, 0.8587187, 0.15365739, 0.2423255...  \n",
       "..              ...                                                ...  \n",
       "70        Computers  [-0.100550376, 0.63713616, 0.069718584, 0.6708...  \n",
       "71            Books  [0.35349807, -0.8391143, 0.31275266, 0.2153156...  \n",
       "72  All Electronics  [-0.38823387, -0.20821722, 0.10322529, -0.0668...  \n",
       "73              NaN  [-0.24847102, 0.30055243, -0.19379012, 0.12391...  \n",
       "74       Automotive  [-0.5370231, -0.16296385, -0.42152908, -0.3307...  \n",
       "\n",
       "[75 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mspecs\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m----> 9\u001b[0m     row \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(row)\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(row\u001b[39m.\u001b[39mtype)\n\u001b[0;32m     11\u001b[0m     row_keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(row\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[39mdel\u001b[39;00m kw[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "data['keys'] = ''\n",
    "data['values'] = ''\n",
    "data['title embeddings'] = ''\n",
    "\n",
    "i = 0\n",
    "for row in data['specs']:\n",
    "    row_keys = list(row.keys())\n",
    "    row_values = list(row.values())\n",
    "    data.at[i, 'keys'] = row_keys\n",
    "    data.at[i, 'values'] = row_values\n",
    "    i += 1\n",
    "\n",
    "a = 0\n",
    "for row in data['title']:\n",
    "    title_embed = model.encode(row)\n",
    "    data.at[a, 'title embeddings'] = title_embed\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basic = data_basic.drop('specs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of title clusters: 1\n",
      "Estimated number of title noise points: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Cluster title embeddings\n",
    "title_embeds = []\n",
    "\n",
    "for row in data['title embeddings']:\n",
    "    title_embeds.append(row)\n",
    "\n",
    "db = DBSCAN(eps=8, min_samples=5).fit(title_embeds)\n",
    "title_labels = db.labels_\n",
    "\n",
    "\n",
    "titles = data['title']\n",
    "specs = data['specs']\n",
    "data_new = list(zip(titles, specs,  title_labels))\n",
    "sorted_titles = pd.DataFrame(data_new, columns=['titles', 'specs', 'cluster_num'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "sorted_titles.to_csv('clusters/sorted_titles_mave.csv')\n",
    "sorted_titles\n",
    "\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of title noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data['title']\n",
    "keys = data['keys']\n",
    "data = list(zip(titles, keys, title_labels))\n",
    "sorted_titles = pd.DataFrame(data, columns=['titles', 'keys', 'cluster_num'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "sorted_titles.to_csv('clusters/sorted_titles_mave.csv')\n",
    "sorted_titles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN over 10 first MAE dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-000.json\n",
      "df shape2173:(2173, 4)\n",
      "res shape2173:(2173, 4)\n",
      "dataset-001.json\n",
      "df shape2351:(2351, 4)\n",
      "res shape2351:(4524, 4)\n",
      "dataset-002.json\n",
      "df shape2281:(2281, 4)\n",
      "res shape2281:(6805, 4)\n",
      "dataset-003.json\n",
      "df shape2260:(2260, 4)\n",
      "res shape2260:(9065, 4)\n",
      "dataset-004.json\n",
      "df shape2314:(2314, 4)\n",
      "res shape2314:(11379, 4)\n",
      "dataset-005.json\n",
      "df shape2161:(2161, 4)\n",
      "res shape2161:(13540, 4)\n",
      "dataset-006.json\n",
      "df shape2332:(2332, 4)\n",
      "res shape2332:(15872, 4)\n",
      "dataset-007.json\n",
      "df shape2224:(2224, 4)\n",
      "res shape2224:(18096, 4)\n",
      "dataset-008.json\n",
      "df shape2305:(2305, 4)\n",
      "res shape2305:(20401, 4)\n",
      "dataset-009.json\n",
      "df shape2264:(2264, 4)\n",
      "res shape2264:(22665, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir('data/train')\n",
    "index = 0\n",
    "for i in range(10):\n",
    "    filename = files[i]\n",
    "    print(filename)\n",
    "    df = pd.read_json(f'data/train/{filename}')\n",
    "    df = df.drop(['tokens', 'diffbotUri', 'text', 'images'], axis=1)\n",
    "\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    df['keys'] = ''\n",
    "    df['values'] = ''\n",
    "    df['title embeddings'] = ''\n",
    "\n",
    "    i = 0\n",
    "    for row in df['specs']:\n",
    "        row_keys = list(row.keys())\n",
    "        row_values = list(row.values())\n",
    "        df.at[i, 'keys'] = row_keys\n",
    "        df.at[i, 'values'] = row_values\n",
    "        i += 1\n",
    "\n",
    "    a = 0\n",
    "    for row in df['title']:\n",
    "        title_embed = model.encode(row)\n",
    "        df.at[a, 'title embeddings'] = title_embed\n",
    "        a += 1\n",
    "\n",
    "\n",
    "    df = df.drop('specs', axis=1)\n",
    "    res = res._append(df)\n",
    "    print(f'df shape{i}:{df.shape}')\n",
    "    print(f'res shape{i}:{res.shape}')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19210, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = res.drop_duplicates(subset='title')\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "outliers = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(19093, 3)\n",
      "(117, 3)\n",
      "Estimated number of title clusters: 9\n",
      "Estimated number of title noise points: 12532\n",
      "(19093, 3)\n",
      "(19093, 3)\n",
      "1\n",
      "(19093, 3)\n",
      "(117, 3)\n",
      "Estimated number of title clusters: 9\n",
      "Estimated number of title noise points: 12532\n",
      "(38186, 3)\n",
      "(38186, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "# Cluster title embeddings (combined 10 MAE data parts)\n",
    "\n",
    "num_out = len(res)\n",
    "i = 0\n",
    "\n",
    "while num_out > len(res)*0.01:\n",
    "    print(i)\n",
    "    title_embeds = []\n",
    "\n",
    "    for row in res['title embeddings']:\n",
    "        title_embeds.append(row)\n",
    "\n",
    "    db = DBSCAN(eps=5, min_samples=10).fit(title_embeds)\n",
    "    title_labels = db.labels_\n",
    "\n",
    "    titles = res['title']\n",
    "    keys = res['keys']\n",
    "    df_new = list(zip(titles, keys,  title_labels))\n",
    "    sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num'])\n",
    "    sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "    outsiders = sorted_titles[sorted_titles.cluster_num <= 0]\n",
    "    print(outsiders.shape)\n",
    "    clusters = sorted_titles[sorted_titles.cluster_num > 0]\n",
    "    print(clusters.shape)\n",
    "    #sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "    n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "    print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "    print(\"Estimated number of title noise points: %d\" % n_noise_)\n",
    "\n",
    "    outliers = outliers._append(outsiders)\n",
    "    print(outliers.shape) \n",
    "    final = final._append(clusters)\n",
    "    print(outliers.shape)\n",
    "\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(19210, 4)\n",
      "(0, 4)\n",
      "(0, 4)\n",
      "Estimated number of title clusters: 1\n",
      "Estimated number of title noise points: 0\n",
      "1\n",
      "(18866, 4)\n",
      "(344, 4)\n",
      "(344, 4)\n",
      "Estimated number of title clusters: 46\n",
      "Estimated number of title noise points: 11456\n",
      "2\n",
      "(18866, 4)\n",
      "(0, 4)\n",
      "(344, 4)\n",
      "Estimated number of title clusters: 1\n",
      "Estimated number of title noise points: 11456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "final = pd.DataFrame()\n",
    "outliers = pd.DataFrame()\n",
    "\n",
    "# Cluster title embeddings (combined 10 MAE data parts)\n",
    "\n",
    "num_out = len(res)\n",
    "i = 0\n",
    "\n",
    "if i == 0:\n",
    "    print(i)\n",
    "    title_embeds = []\n",
    "\n",
    "    for row in res['title embeddings']:\n",
    "        title_embeds.append(row)\n",
    "\n",
    "    db = DBSCAN(eps=25, min_samples=10).fit(title_embeds)\n",
    "    title_labels = db.labels_\n",
    "\n",
    "    titles = res['title']\n",
    "    keys = res['keys']\n",
    "    title_embed = res['title embeddings']\n",
    "    df_new = list(zip(titles, keys,  title_labels, title_embed))\n",
    "    sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num', 'title_embeds'])\n",
    "    sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "    outliers = sorted_titles[sorted_titles.cluster_num <= 0]\n",
    "    print(outliers.shape)\n",
    "    clusters = sorted_titles[sorted_titles.cluster_num > 0]\n",
    "    print(clusters.shape)\n",
    "    #sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "    final = final._append(clusters)\n",
    "    print(final.shape)\n",
    "\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "    n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "    print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "    print(\"Estimated number of title noise points: %d\" % n_noise_)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "if i != 0:\n",
    "    \n",
    "    while num_out > len(res)*0.01:\n",
    "        print(i)\n",
    "        title_embeds = []\n",
    "\n",
    "        for row in outliers['title_embeds']:\n",
    "            title_embeds.append(row)\n",
    "\n",
    "        db = DBSCAN(eps=5, min_samples=5).fit(title_embeds)\n",
    "        title_labels = db.labels_\n",
    "\n",
    "        titles = outliers['titles']\n",
    "        keys = outliers['keys']\n",
    "        title_embed = outliers['title_embeds']\n",
    "        df_new = list(zip(titles, keys,  title_labels, title_embed))\n",
    "        sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num', 'title_embeds'])\n",
    "        sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "        outliers = sorted_titles[sorted_titles.cluster_num <= 0]\n",
    "        print(outliers.shape)\n",
    "        clusters = sorted_titles[sorted_titles.cluster_num > 0]\n",
    "        print(clusters.shape)\n",
    "        #sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "        final = final._append(clusters)\n",
    "        print(final.shape)\n",
    "\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "        n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "        print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "        print(\"Estimated number of title noise points: %d\" % n_noise_)\n",
    "\n",
    "        \n",
    "        if i == 2:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18592, 4)\n",
      "(238, 4)\n",
      "(618, 4)\n",
      "Estimated number of title clusters: 31\n",
      "Estimated number of title noise points: 18587\n"
     ]
    }
   ],
   "source": [
    "title_embeds = []\n",
    "\n",
    "for row in outliers['title_embeds']:\n",
    "    title_embeds.append(row)\n",
    "\n",
    "db = DBSCAN(eps=3, min_samples=5).fit(title_embeds)\n",
    "title_labels = db.labels_\n",
    "\n",
    "titles = outliers['titles']\n",
    "keys = outliers['keys']\n",
    "title_embed = outliers['title_embeds']\n",
    "df_new = list(zip(titles, keys,  title_labels, title_embed))\n",
    "sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num', 'title_embeds'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "outliers = sorted_titles[sorted_titles.cluster_num <= 0]\n",
    "print(outliers.shape)\n",
    "clusters = sorted_titles[sorted_titles.cluster_num > 0]\n",
    "print(clusters.shape)\n",
    "#sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "final = final._append(clusters)\n",
    "print(final.shape)\n",
    "\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of title noise points: %d\" % n_noise_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>keys</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>title_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>LOGO Littles by Lori Goldstein Twin Set Peplum...</td>\n",
       "      <td>[care, content]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4017361, 0.40387478, -0.09297889, -0.02499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19022</th>\n",
       "      <td>LOGO Layers by Lori Goldstein Knit Top with As...</td>\n",
       "      <td>[care, fabrication, content]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.482689, 0.46908173, 0.021570066, -0.114965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15370</th>\n",
       "      <td>LOGO by Lori Goldstein Slub Knit Top w/ Pocket...</td>\n",
       "      <td>[care, fabrication, content]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.45227563, 0.6994751, -0.113412365, -0.0644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885</th>\n",
       "      <td>LOGO by Lori Goldstein Solid Tank with Embroid...</td>\n",
       "      <td>[care, fabrication]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2240108, 0.6168129, -0.0020393194, -0.2156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>LOGO by Lori Goldstein Stripe Cardigan with Sc...</td>\n",
       "      <td>[care, fabrication]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1291526, 0.3764324, 0.031848762, -0.140958...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15962</th>\n",
       "      <td>New 2017 Nissan Sentra S</td>\n",
       "      <td>[bumpers, rear_defogger, clock, traction_contr...</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.32505292, -0.0055744834, -0.44062233, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15715</th>\n",
       "      <td>2015 Nissan Sentra</td>\n",
       "      <td>[location, model, sellerid]</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.37110183, -0.16539957, -0.39887533, -0.209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18470</th>\n",
       "      <td>2016 Nissan Sentra</td>\n",
       "      <td>[warranty]</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.20286049, -0.12241865, -0.49883828, -0.223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14067</th>\n",
       "      <td>2006 Nissan Sentra</td>\n",
       "      <td>[model]</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.18924849, -0.18312676, -0.657961, -0.15840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14900</th>\n",
       "      <td>2012 Nissan Sentra</td>\n",
       "      <td>[drive_type, fuel, doors, interior, transmission]</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.26353553, -0.18917155, -0.54990315, -0.259...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  titles  \\\n",
       "7914   LOGO Littles by Lori Goldstein Twin Set Peplum...   \n",
       "19022  LOGO Layers by Lori Goldstein Knit Top with As...   \n",
       "15370  LOGO by Lori Goldstein Slub Knit Top w/ Pocket...   \n",
       "12885  LOGO by Lori Goldstein Solid Tank with Embroid...   \n",
       "12066  LOGO by Lori Goldstein Stripe Cardigan with Sc...   \n",
       "...                                                  ...   \n",
       "15962                           New 2017 Nissan Sentra S   \n",
       "15715                                 2015 Nissan Sentra   \n",
       "18470                                 2016 Nissan Sentra   \n",
       "14067                                 2006 Nissan Sentra   \n",
       "14900                                 2012 Nissan Sentra   \n",
       "\n",
       "                                                    keys  cluster_num  \\\n",
       "7914                                     [care, content]            1   \n",
       "19022                       [care, fabrication, content]            1   \n",
       "15370                       [care, fabrication, content]            1   \n",
       "12885                                [care, fabrication]            1   \n",
       "12066                                [care, fabrication]            1   \n",
       "...                                                  ...          ...   \n",
       "15962  [bumpers, rear_defogger, clock, traction_contr...           30   \n",
       "15715                        [location, model, sellerid]           30   \n",
       "18470                                         [warranty]           30   \n",
       "14067                                            [model]           30   \n",
       "14900  [drive_type, fuel, doors, interior, transmission]           30   \n",
       "\n",
       "                                            title_embeds  \n",
       "7914   [-0.4017361, 0.40387478, -0.09297889, -0.02499...  \n",
       "19022  [-0.482689, 0.46908173, 0.021570066, -0.114965...  \n",
       "15370  [-0.45227563, 0.6994751, -0.113412365, -0.0644...  \n",
       "12885  [-0.2240108, 0.6168129, -0.0020393194, -0.2156...  \n",
       "12066  [-0.1291526, 0.3764324, 0.031848762, -0.140958...  \n",
       "...                                                  ...  \n",
       "15962  [-0.32505292, -0.0055744834, -0.44062233, -0.1...  \n",
       "15715  [-0.37110183, -0.16539957, -0.39887533, -0.209...  \n",
       "18470  [-0.20286049, -0.12241865, -0.49883828, -0.223...  \n",
       "14067  [-0.18924849, -0.18312676, -0.657961, -0.15840...  \n",
       "14900  [-0.26353553, -0.18917155, -0.54990315, -0.259...  \n",
       "\n",
       "[618 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(final)\n",
    "final = final.drop(['title_embeds'], axis=1)\n",
    "final.to_csv('inkijk_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1, 3)\n",
      "(19209, 3)\n",
      "Estimated number of title clusters: 4919\n",
      "Estimated number of title noise points: 0\n",
      "(18873, 4)\n",
      "(18873, 4)\n",
      "1\n",
      "(1, 3)\n",
      "(19209, 3)\n",
      "Estimated number of title clusters: 4919\n",
      "Estimated number of title noise points: 0\n",
      "(18874, 4)\n",
      "(18874, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "\n",
    "# Cluster title embeddings (combined 10 MAE data parts)\n",
    "\n",
    "num_out = len(outliers)\n",
    "i = 0\n",
    "\n",
    "while num_out > len(res)*0.01:\n",
    "    print(i)\n",
    "    title_embeds = []\n",
    "\n",
    "    for row in res['title embeddings']:\n",
    "        title_embeds.append(row)\n",
    "\n",
    "    db = Birch(threshold=5, n_clusters=None).fit(title_embeds)\n",
    "    title_labels = db.labels_\n",
    "\n",
    "    titles = res['title']\n",
    "    keys = res['keys']\n",
    "    df_new = list(zip(titles, keys,  title_labels))\n",
    "    sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num'])\n",
    "    sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "    outsiders = sorted_titles[sorted_titles.cluster_num <= 0]\n",
    "    print(outsiders.shape)\n",
    "    clusters = sorted_titles[sorted_titles.cluster_num > 0]\n",
    "    print(clusters.shape)\n",
    "    sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "    n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "    print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "    print(\"Estimated number of title noise points: %d\" % n_noise_)\n",
    "\n",
    "    outliers = outliers._append(outsiders)\n",
    "    print(outliers.shape) \n",
    "    final = final._append(clusters)\n",
    "    print(outliers.shape)\n",
    "\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing parameters\n",
    "https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import cluster\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = res['title embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m neighbors \u001b[39m=\u001b[39m NearestNeighbors(n_neighbors\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m neighbors_fit \u001b[39m=\u001b[39m neighbors\u001b[39m.\u001b[39;49mfit(out)\n\u001b[0;32m      3\u001b[0m distances, indices \u001b[39m=\u001b[39m neighbors_fit\u001b[39m.\u001b[39mkneighbors(out)\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:176\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \n\u001b[0;32m    161\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m    The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\sklearn\\neighbors\\_base.py:491\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 491\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    493\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nina W\\Documents\\uni\\thesis_nina\\lib\\site-packages\\pandas\\core\\series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    916\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m--> 917\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    919\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=10)\n",
    "neighbors_fit = neighbors.fit(out)\n",
    "distances, indices = neighbors_fit.kneighbors(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhoutte score\n",
    "https://medium.com/@tarammullin/dbscan-2788cfce9389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps and min_smaples need to be determined\n",
    "\n",
    "eps = 225\n",
    "min_samples = 20\n",
    "dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples)\n",
    "clustering_labels = dbscan.fit_predict(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = clustering_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.silhouette_score(df, df['labels'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
