{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\envs\\thesis1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_mave/data_in_mave_0.json', 'r') as datafile:\n",
    "    data = json.load(datafile)\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "data\n",
    "\n",
    "#data = pd.read_json('data_in_mave_0.json', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "data['title embeddings'] = ''\n",
    "\n",
    "a = 0\n",
    "for row in data['title']:\n",
    "    title_embed = model.encode(row)\n",
    "    data.at[a, 'title embeddings'] = title_embed\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "data['keys'] = ''\n",
    "data['values'] = ''\n",
    "data['title embeddings'] = ''\n",
    "\n",
    "i = 0\n",
    "for row in data['specs']:\n",
    "    row_keys = list(row.keys())\n",
    "    row_values = list(row.values())\n",
    "    data.at[i, 'keys'] = row_keys\n",
    "    data.at[i, 'values'] = row_values\n",
    "    i += 1\n",
    "\n",
    "a = 0\n",
    "for row in data['title']:\n",
    "    title_embed = model.encode(row)\n",
    "    data.at[a, 'title embeddings'] = title_embed\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basic = data_basic.drop('specs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Cluster title embeddings\n",
    "title_embeds = []\n",
    "\n",
    "for row in data['title embeddings']:\n",
    "    title_embeds.append(row)\n",
    "\n",
    "db = DBSCAN(eps=8, min_samples=5).fit(title_embeds)\n",
    "title_labels = db.labels_\n",
    "\n",
    "\n",
    "titles = data['title']\n",
    "specs = data['specs']\n",
    "data_new = list(zip(titles, specs,  title_labels))\n",
    "sorted_titles = pd.DataFrame(data_new, columns=['titles', 'specs', 'cluster_num'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "sorted_titles.to_csv('clusters/sorted_titles_mave.csv')\n",
    "sorted_titles\n",
    "\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of title noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data['title']\n",
    "keys = data['keys']\n",
    "data = list(zip(titles, keys, title_labels))\n",
    "sorted_titles = pd.DataFrame(data, columns=['titles', 'keys', 'cluster_num'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "sorted_titles.to_csv('clusters/sorted_titles_mave.csv')\n",
    "sorted_titles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN over 10 first MAE dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-000.json\n",
      "df shape2173:(2173, 4)\n",
      "res shape2173:(2173, 4)\n",
      "dataset-001.json\n",
      "df shape2351:(2351, 4)\n",
      "res shape2351:(4524, 4)\n",
      "dataset-002.json\n",
      "df shape2281:(2281, 4)\n",
      "res shape2281:(6805, 4)\n",
      "dataset-003.json\n",
      "df shape2260:(2260, 4)\n",
      "res shape2260:(9065, 4)\n",
      "dataset-004.json\n",
      "df shape2314:(2314, 4)\n",
      "res shape2314:(11379, 4)\n",
      "dataset-005.json\n",
      "df shape2161:(2161, 4)\n",
      "res shape2161:(13540, 4)\n",
      "dataset-006.json\n",
      "df shape2332:(2332, 4)\n",
      "res shape2332:(15872, 4)\n",
      "dataset-007.json\n",
      "df shape2224:(2224, 4)\n",
      "res shape2224:(18096, 4)\n",
      "dataset-008.json\n",
      "df shape2305:(2305, 4)\n",
      "res shape2305:(20401, 4)\n",
      "dataset-009.json\n",
      "df shape2264:(2264, 4)\n",
      "res shape2264:(22665, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir('data/train')\n",
    "index = 0\n",
    "for i in range(10):\n",
    "    filename = files[i]\n",
    "    print(filename)\n",
    "    df = pd.read_json(f'data/train/{filename}')\n",
    "    df = df.drop(['tokens', 'diffbotUri', 'text', 'images'], axis=1)\n",
    "\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    df['keys'] = ''\n",
    "    df['values'] = ''\n",
    "    df['title embeddings'] = ''\n",
    "\n",
    "    i = 0\n",
    "    for row in df['specs']:\n",
    "        row_keys = list(row.keys())\n",
    "        row_values = list(row.values())\n",
    "        df.at[i, 'keys'] = row_keys\n",
    "        df.at[i, 'values'] = row_values\n",
    "        i += 1\n",
    "\n",
    "    a = 0\n",
    "    for row in df['title']:\n",
    "        title_embed = model.encode(row)\n",
    "        df.at[a, 'title embeddings'] = title_embed\n",
    "        a += 1\n",
    "\n",
    "\n",
    "    df = df.drop('specs', axis=1)\n",
    "    res = res.append(df)\n",
    "    print(f'df shape{i}:{df.shape}')\n",
    "    print(f'res shape{i}:{res.shape}')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19210, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = res.drop_duplicates(subset='title')\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of title clusters: 46\n",
      "Estimated number of title noise points: 11456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Cluster title embeddings (combined 10 MAE data parts)\n",
    "title_embeds = []\n",
    "\n",
    "for row in res['title embeddings']:\n",
    "    title_embeds.append(row)\n",
    "\n",
    "db = DBSCAN(eps=5, min_samples=5).fit(title_embeds)\n",
    "title_labels = db.labels_\n",
    "\n",
    "titles = res['title']\n",
    "keys = res['keys']\n",
    "df_new = list(zip(titles, keys,  title_labels))\n",
    "sorted_titles = pd.DataFrame(df_new, columns=['titles', 'keys', 'cluster_num'])\n",
    "sorted_titles = sorted_titles.sort_values(by=['cluster_num'])\n",
    "sorted_titles.to_csv('clusters/sorted_titles_mae10.csv')\n",
    "sorted_titles\n",
    "\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(title_labels)) - (1 if -1 in title_labels else 0)\n",
    "n_noise_ = list(title_labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of title clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of title noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_nina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
